{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSGO round winner prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is CSGO?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> CSGO(Counter Strike Global-Offencive) is a round based tactical shooter between CT(Counter terrorist) and T(Terrorist) where we buy equipments usig in game cash that is provided by the game in each round. The overall goal is that the terrorist must plant a bomb while the counter terrorist must stop them or defuse the bomb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csgo_round_snapshots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # finding nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['round_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for columns for only one value\n",
    "t=[]\n",
    "for i in col:\n",
    "    t.append(df[i].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the columns with only one value\n",
    "temp =[]\n",
    "for i in range(len(t)):\n",
    "    if t[i]==1:\n",
    "        temp.append(i)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df[col[22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([col[22], col[30], col[37], col[52], col[58], col[60]], axis = 1, inplace = True) # dropping those columns\n",
    "print(col[22])\n",
    "print(col[30])\n",
    "print(col[37])\n",
    "print(col[52])\n",
    "print(col[58])\n",
    "print(col[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label encoding all categorical values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder() \n",
    "df['map'] = label_encoder.fit_transform(df['map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bomb_planted'] = label_encoder.fit_transform(df['bomb_planted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['round_winner'] = label_encoder.fit_transform(df['round_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for i in col:\n",
    "    c.append(df['round_winner'].corr(df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data using Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standscl = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standscl.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standscl.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = standscl.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df, columns = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['round_winner'] = label_encoder.fit_transform(df['round_winner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('round_winner', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['round_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LogisticRegression()\n",
    "model_1.fit(x_train,y_train)\n",
    "pred_1 = model_1.predict(x_test)\n",
    "cr1    = classification_report(y_test,pred_1)\n",
    "print(cr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = DecisionTreeClassifier()\n",
    "model_2.fit(x_train,y_train)\n",
    "pred_2 = model_2.predict(x_test)\n",
    "cr2 = classification_report(y_test,pred_2)\n",
    "print(cr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(x_train,y_train)\n",
    "pred_3 = model_3.predict(x_test)\n",
    "cr3 = classification_report(y_test,pred_3)\n",
    "print(cr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = XGBClassifier()\n",
    "model_4.fit(x_train,y_train)\n",
    "pred_4 = model_4.predict(x_test)\n",
    "cr4 = classification_report(y_test,pred_4)\n",
    "print(cr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = MLPClassifier()\n",
    "model_5.fit(x_train,y_train)\n",
    "pred_5 = model_5.predict(x_test)\n",
    "cr5 = classification_report(y_test,pred_5)\n",
    "print(cr5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal accuracy for random forest classifier:', str(accuracy_score(y_test,pred_3)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy scores of each model\n",
    "scores = [accuracy_score(y_test, pred_1), accuracy_score(y_test, pred_2), accuracy_score(y_test, pred_3), accuracy_score(y_test, pred_4), accuracy_score(y_test, pred_5)]\n",
    "\n",
    "# Names of each model\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'Neural Network']\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(names, scores)\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Accuracy Scores of Different Models', color='white')\n",
    "plt.xlabel('Model', color='white')\n",
    "plt.ylabel('Accuracy Score', color='white')\n",
    "\n",
    "# Set the color of the text in the plot\n",
    "plt.xticks(color='white')\n",
    "plt.yticks(color='white')\n",
    "\n",
    "# Set the color of the plot background\n",
    "plt.rcParams['figure.facecolor'] = 'black'\n",
    "\n",
    "# Rotate the x-axis labels and increase spacing between them\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tick_params(axis='x', pad=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "# Set the figure size\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 6)\n",
    "\n",
    "# Save the plot in png format with 300 dpi resolution\n",
    "plt.savefig('accuracy_scores.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an instance of SVM\n",
    "svm = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "\n",
    "# Train the model\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "pred_svm = svm.predict(x_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "acc_svm = accuracy_score(y_test, pred_svm)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(f\"SVM Accuracy Score: {acc_svm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
